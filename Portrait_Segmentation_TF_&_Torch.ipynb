{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pn9hhkC9hBcd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from glob import glob\n",
        "from tqdm.notebook import tqdm_notebook as tqdm \n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3Dz6RgbhBch"
      },
      "source": [
        "### Mount drive and extract Zip from drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zQQ-kjFhBcj"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmN4YTR4hBcj"
      },
      "outputs": [],
      "source": [
        "# Extract the contents of zip file to current directory\n",
        "zip_path = os.path.join(os.getcwd(),\"drive\",\"MyDrive\",\"dataset.zip\")\n",
        "zip_ref = zipfile.ZipFile(zip_path, 'r')\n",
        "zip_ref.extractall(os.getcwd())\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sawxCqPbhBck"
      },
      "outputs": [],
      "source": [
        "os.makedirs('./saved_model/tf2', exist_ok=True)\n",
        "os.makedirs('./saved_model/keras', exist_ok=True)\n",
        "os.makedirs('./saved_model/pytorch', exist_ok=True)\n",
        "os.makedirs('./saved_model/torchscript', exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqT830CvhBck"
      },
      "source": [
        "### Read images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sd2Ib9DFhBcl"
      },
      "outputs": [],
      "source": [
        "# train set\n",
        "source_images_path = os.path.join(os.getcwd(),\"dataset\", \"training\", \"images\")\n",
        "source_masks_path = os.path.join(os.getcwd(),\"dataset\", \"training\", \"masks\")\n",
        "\n",
        "source_images = sorted(glob(os.path.join(source_images_path,\"*\")))\n",
        "source_masks = sorted(glob(os.path.join(source_masks_path,\"*\")))\n",
        "\n",
        "source_images = shuffle(source_images, random_state=1024)\n",
        "source_masks = shuffle(source_masks, random_state=1024)\n",
        "\n",
        "\n",
        "# test_set\n",
        "test_images_path = os.path.join(os.getcwd(),\"dataset\", \"testing\", \"images\")\n",
        "test_masks_path = os.path.join(os.getcwd(),\"dataset\", \"testing\", \"masks\")\n",
        "\n",
        "test_images = sorted(glob(os.path.join(test_images_path,\"*\")))\n",
        "test_masks = sorted(glob(os.path.join(test_masks_path,\"*\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLB_2XHlhBcm"
      },
      "source": [
        "### Create Train and Val dataset splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRKvPfJZhBcm"
      },
      "outputs": [],
      "source": [
        "def create_split(source_images, source_masks):\n",
        "    train_x, val_x = train_test_split(source_images, test_size=0.05, random_state=77)\n",
        "    train_y, val_y = train_test_split(source_masks, test_size=0.05, random_state=77)\n",
        "    \n",
        "    return (train_x, train_y), (val_x, val_y)\n",
        "\n",
        "(train_x, train_y), (val_x, val_y) = create_split(source_images, source_masks)\n",
        "\n",
        "print(f\"TrainX: {len(train_x)} TrainY: {len(train_y)}\")\n",
        "print(f\"TestX: {len(val_x)} TestX: {len(val_y)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qZoTUWRhBcn"
      },
      "source": [
        "### Image and Mask read functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLbj8IvNhBco"
      },
      "outputs": [],
      "source": [
        "def read_image(path, _format=None):\n",
        "    \"\"\" Read image, resize and scale\"\"\"\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
        "    x = cv2.resize(x, (H, W))\n",
        "    x = x / 255.0\n",
        "    x = x.astype(np.float32)\n",
        "    \n",
        "    if _format == 'channel_first':\n",
        "        x = np.moveaxis(x, -1, 0)\n",
        "        \n",
        "    return x\n",
        "\n",
        "def read_mask(path, _format=None):\n",
        "    \"\"\" Read mask and resize and scale\"\"\"\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    x = cv2.resize(x, (H, W))\n",
        "    x = x / 255.0\n",
        "    x = x.astype(np.float32)\n",
        "    x = np.expand_dims(x, axis=-1)\n",
        "    \n",
        "    if _format == 'channel_first':\n",
        "        x = np.moveaxis(x, -1, 0)\n",
        "        \n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5exHJY7ThBco"
      },
      "source": [
        "# ------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS_6f4u-hBcp"
      },
      "source": [
        "# Tensorflow/ Keras Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhudYzFKhBcq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import CustomObjectScope"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBmYAKDDhBcq"
      },
      "outputs": [],
      "source": [
        "H, W = 224, 224   # Image height and width \n",
        "INPUT_CHANNEL = 3 \n",
        "OUTPUT_CHANNEL = 1\n",
        "INPUT_SHAPE = (H, W, INPUT_CHANNEL)\n",
        "\n",
        "# Hyper parameters\n",
        "batch_size = 8\n",
        "lr = 1e-4\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0aIX3QhhBcr"
      },
      "source": [
        "### Data preprocessing pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6AjtajyhBcr"
      },
      "outputs": [],
      "source": [
        "def preprocess(image_path, mask_path):\n",
        "    \"\"\" Preprocess image and mask\"\"\"\n",
        "    def f(image_path, mask_path):\n",
        "        image_path = image_path.decode()\n",
        "        mask_path = mask_path.decode()\n",
        "        \n",
        "        x = read_image(image_path)\n",
        "        y = read_mask(mask_path)\n",
        "\n",
        "        return x, y\n",
        "    \n",
        "    image, mask = tf.numpy_function(f, [image_path, mask_path], [tf.float32, tf.float32])\n",
        "    image.set_shape([H, W, INPUT_CHANNEL])\n",
        "    mask.set_shape([H, W, OUTPUT_CHANNEL])\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "def tf_dataset(images, masks, batch):\n",
        "    \"\"\" tf data processing \"\"\"\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, masks))\n",
        "    dataset = dataset.shuffle(buffer_size=batch*40)\n",
        "    dataset = dataset.map(preprocess)\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0d9u56ZhBcs"
      },
      "outputs": [],
      "source": [
        "# Create tf.data\n",
        "train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
        "val_dataset = tf_dataset(val_x, val_y, batch=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtZwMF0QhBcs"
      },
      "source": [
        "### UNet model - Encoder: VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2Ki0ovWhBcs"
      },
      "outputs": [],
      "source": [
        "def conv_block(inputs, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\", use_bias=False)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\", use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def decoder_block(inputs, skip, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
        "    x = Concatenate()([x, skip])\n",
        "    x = conv_block(x, num_filters)\n",
        "\n",
        "    return x\n",
        "\n",
        "def build_vgg16_unet_tf(input_shape):    \n",
        "    \"\"\" Input \"\"\"\n",
        "    inputs = Input(shape=input_shape)    ## (224, 224, 3)\n",
        "\n",
        "    \"\"\" Pre-trained VGG16 \"\"\"\n",
        "    encoder = VGG16(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "    \n",
        "    \"\"\" freeze encoder layers \"\"\"\n",
        "    for layer in encoder.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "\n",
        "    \"\"\" Encoder \"\"\"\n",
        "    s1 = encoder.get_layer(\"block1_conv2\").output    ## (224 x 224)\n",
        "    s2 = encoder.get_layer(\"block2_conv2\").output    ## (112 x 112)\n",
        "    s3 = encoder.get_layer(\"block3_conv3\").output    ## (56 x 56)\n",
        "    s4 = encoder.get_layer(\"block4_conv3\").output    ## (28 x 28)\n",
        "\n",
        "    \"\"\" Bridge \"\"\"\n",
        "    b1 = encoder.get_layer(\"block5_conv3\").output    ## (14 x 14)\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    d1 = decoder_block(b1, s4, 512)                  ## (28 x 28)\n",
        "    d2 = decoder_block(d1, s3, 256)                  ## (56 x 56)\n",
        "    d3 = decoder_block(d2, s2, 128)                  ## (112 x 112)\n",
        "    d4 = decoder_block(d3, s1, 64)                   ## (224 x 224)\n",
        "\n",
        "    \"\"\" Output \"\"\"\n",
        "    outputs = Conv2D(OUTPUT_CHANNEL, 1, padding=\"same\", activation=\"sigmoid\")(d4) ## (224, 224, 1)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"VGG16_U-Net\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2UtmjuXhBct"
      },
      "outputs": [],
      "source": [
        "# Build UNet Model with VGG16 as Encoder\n",
        "model_tf = build_vgg16_unet_tf(INPUT_SHAPE)\n",
        "model_tf.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri3EaZyGhBct"
      },
      "source": [
        "### Metric, Compile and callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPvGPpb8hBcu"
      },
      "outputs": [],
      "source": [
        "# Dice Coefficient Metric\n",
        "def dice_coef(y_true, y_pred, smooth=1.):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_3lOp2khBcu"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model_tf.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.Adam(lr),\n",
        "    metrics=[\n",
        "        tf.keras.metrics.Recall(),\n",
        "        tf.keras.metrics.Precision(),\n",
        "        \"accuracy\",\n",
        "        dice_coef\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNfpjKcbhBcv"
      },
      "source": [
        "### Training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KYTycmyhBcv"
      },
      "outputs": [],
      "source": [
        "train_steps = len(train_x) // batch_size\n",
        "val_steps = len(val_x) // batch_size\n",
        "\n",
        "if len(train_x) % batch_size != 0:\n",
        "    train_steps += 1\n",
        "\n",
        "if len(val_x) % batch_size != 0:\n",
        "    val_steps += 1\n",
        "\n",
        "history = model_tf.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=num_epochs,\n",
        "    steps_per_epoch=train_steps,\n",
        "    validation_steps=val_steps,\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ety7dRcthBcv"
      },
      "source": [
        "### Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwRM-bNChBcv"
      },
      "outputs": [],
      "source": [
        "# save as tf2 format \n",
        "tf.saved_model.save(model_tf, './saved_model/tf2')\n",
        "\n",
        "# save as keras format\n",
        "model_tf.save(\"./saved_model/keras/model_keras.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxMDW-rihBcv"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSkNKwVjhBcv"
      },
      "outputs": [],
      "source": [
        "with CustomObjectScope({'dice_coef': dice_coef}):\n",
        "    model_tf = tf.keras.models.load_model(\"./saved_model/keras/model_keras.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_qIgUXahBcw"
      },
      "source": [
        "### Loss and Metrics Visualization "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0vr6XvNhBcw"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "dice_coef = history.history['dice_coef']\n",
        "val_dice_coef = history.history['val_dice_coef']\n",
        "epochs = range(len(acc))\n",
        "\n",
        "# Accuracy\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "# Loss\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "# Dice Coef\n",
        "plt.plot(epochs, dice_coef, 'r', label='Training Dice coef')\n",
        "plt.plot(epochs, val_dice_coef, 'b', label='Validation Dice coef')\n",
        "plt.title('Training and validation dice coef')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wopRkfkEhBcw"
      },
      "source": [
        "### Evaluation (on test set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smpGOlEhhBcw"
      },
      "outputs": [],
      "source": [
        "def intersection_over_union(y_true, y_pred):\n",
        "    \"\"\" Function to calculate IOU \"\"\"\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true.ravel(), y_pred.ravel()).ravel()\n",
        "    iou = tp/(tp + fp + fn)\n",
        "    return iou\n",
        "\n",
        "\n",
        "def save_results(image, mask, y_pred, save_image_path):\n",
        "    \"\"\" Fucntion that saves the original image, ground truth mask, predicted mask\"\"\"\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    line = np.ones((H, 10, 3)) * 128\n",
        "\n",
        "    mask = np.expand_dims(mask, axis=-1)    # (224, 224, 1)\n",
        "    mask = np.concatenate([mask, mask, mask], axis=-1)  # (224, 224, 3)\n",
        "    mask = mask * 255\n",
        "\n",
        "    y_pred = np.expand_dims(y_pred, axis=-1)    # (224, 224, 1)\n",
        "    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1)  # (224, 224, 3)\n",
        "    y_pred = y_pred * 255\n",
        "\n",
        "    cat_images = np.concatenate([image, line, mask, line, y_pred], axis=1)\n",
        "    cv2.imwrite(save_image_path, cat_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37zIh07mhBcw"
      },
      "outputs": [],
      "source": [
        "# Evaluation on test set\n",
        "SCORE = []\n",
        "for x, y in tqdm(zip(test_images, test_masks), total=len(test_masks)):\n",
        "    # Extract the name\n",
        "    if os.name == 'nt': # windows\n",
        "        name = x.split(\"\\\\\")[-1].split(\".\")[0]\n",
        "    else: # Linux\n",
        "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
        "    \n",
        "    # Reading the image\n",
        "    image = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (H, W))\n",
        "    x = image/255.0\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    # Reading the mask\n",
        "    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
        "    mask = mask/255.0\n",
        "    mask = cv2.resize(mask, (H, W))\n",
        "    mask = mask.astype(np.int32)\n",
        "\n",
        "    # Prediction\n",
        "    y_pred = model_tf.predict(x)[0]\n",
        "    y_pred = np.squeeze(y_pred, axis=-1)\n",
        "    y_pred = y_pred > 0.5\n",
        "    y_pred = y_pred.astype(np.int32)\n",
        "\n",
        "    # Saving the prediction\n",
        "    save_image_path = os.path.join(\"results\", \"tf_keras\", f\"{name}.png\")\n",
        "    save_results(image, mask, y_pred, save_image_path)\n",
        "\n",
        "    # Flatten the array\n",
        "    mask = mask.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "\n",
        "    # Calculating the metrics values\n",
        "    acc_value = accuracy_score(mask, y_pred)\n",
        "    iou = intersection_over_union(mask, y_pred)\n",
        "    recall_value = recall_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    precision_value = precision_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    SCORE.append([name, acc_value, iou, recall_value, precision_value])\n",
        "\n",
        "# Metrics values\n",
        "score = [s[1:] for s in SCORE]\n",
        "score = np.mean(score, axis=0)\n",
        "print(f\"Accuracy: {score[0]:0.5f}\")\n",
        "print(f\"IOU: {score[1]:0.5f}\")\n",
        "print(f\"Recall: {score[2]:0.5f}\")\n",
        "print(f\"Precision: {score[3]:0.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_3YlYHLhBcx"
      },
      "source": [
        "# ------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2u4X6LwhBcx"
      },
      "source": [
        "# Pytorch Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psdpGjHOhBcx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import vgg16\n",
        "\n",
        "from torchmetrics.functional import accuracy, precision, recall\n",
        "\n",
        "from torch_lr_finder import LRFinder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw1ctqejhBcx"
      },
      "outputs": [],
      "source": [
        "H, W = 224, 224   # Image height and width \n",
        "INPUT_CHANNEL = 3 \n",
        "OUTPUT_CHANNEL = 1\n",
        "INPUT_SHAPE = (INPUT_CHANNEL, H, W)\n",
        "\n",
        "total_train_len = len(train_x)\n",
        "total_val_len = len(val_x)\n",
        "\n",
        "# Hyper parameters\n",
        "batch_size = 8\n",
        "lr = 1e-4\n",
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q89r0vZShBcx"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device, type(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPtGpAYahBcy"
      },
      "source": [
        "### Data preprocessing pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LaGOWHAhBcy"
      },
      "outputs": [],
      "source": [
        "# Inheriting from torch.utils.data.Dataset\n",
        "\n",
        "class DatasetPreprocessor(Dataset):\n",
        "    def __init__(self, inputs: list, targets: list, device: torch.device):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        \n",
        "        # Select the sample\n",
        "        input_ID = self.inputs[index]\n",
        "        target_ID = self.targets[index]\n",
        "\n",
        "        # Read input and target\n",
        "        x = read_image(input_ID, _format='channel_first')\n",
        "        y = read_mask(target_ID, _format='channel_first')\n",
        "\n",
        "        # Typecasting and device\n",
        "        x = torch.from_numpy(x)\n",
        "        y = torch.from_numpy(y)\n",
        "\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mu4yTn5XhBcy"
      },
      "outputs": [],
      "source": [
        "train_dataset = DatasetPreprocessor(train_x, train_y, device)\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "                        dataset=train_dataset, \n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=True, \n",
        "                        num_workers=0,\n",
        "#                         pin_memory=True\n",
        "                    )\n",
        "\n",
        "val_dataset = DatasetPreprocessor(val_x, val_y, device)\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "                    dataset=val_dataset, \n",
        "                    batch_size=batch_size,\n",
        "                    shuffle=False, \n",
        "                    num_workers=0,\n",
        "#                     pin_memory=True\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9eCe7tEhBcy"
      },
      "outputs": [],
      "source": [
        "len(train_dataloader), len(val_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fytJ69RXhBcy"
      },
      "source": [
        "### UNet model - Encoder: VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pv_JV_ShBcy"
      },
      "outputs": [],
      "source": [
        "class conv_block(nn.Module):\n",
        "    \"\"\" \n",
        "    Convolutional block:\n",
        "    It follows a two 3x3 convolutional layer, each followed by a batch normalization and a relu activation.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_c)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_c)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class decoder_block(nn.Module):\n",
        "    \"\"\" \n",
        "    Decoder block:\n",
        "    The decoder block begins with a transpose convolution, followed by a concatenation with the skip\n",
        "    connection from the conv block. Next comes the conv_block.\n",
        "    Here the number filters decreases by half and the height and width doubles.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "\n",
        "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
        "        self.conv = conv_block(2 * out_c, out_c)\n",
        "\n",
        "    def forward(self, inputs, skip):\n",
        "        x = self.up(inputs)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        x = self.conv(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class build_vgg16_unet_torch(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        \"\"\" Pre-trained VGG16 \"\"\"\n",
        "        encoder = vgg16(pretrained=True)\n",
        "        \n",
        "        \"\"\" freeze the encoder layers \"\"\"\n",
        "        for param in encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        \"\"\" Encoder \"\"\"\n",
        "        self.e1 = nn.Sequential(*encoder.features[0:4])\n",
        "        self.e2 = nn.Sequential(*encoder.features[4:9])\n",
        "        self.e3 = nn.Sequential(*encoder.features[9:16])\n",
        "        self.e4 = nn.Sequential(*encoder.features[16:23])\n",
        "\n",
        "        \"\"\" Bottleneck \"\"\"\n",
        "        self.b1 = nn.Sequential(*encoder.features[23:30])\n",
        "\n",
        "        \"\"\" Decoder \"\"\"\n",
        "        self.d1 = decoder_block(512, 512)\n",
        "        self.d2 = decoder_block(512, 256)\n",
        "        self.d3 = decoder_block(256, 128)\n",
        "        self.d4 = decoder_block(128, 64)\n",
        "\n",
        "        \"\"\" Classifier \"\"\"\n",
        "        self.logits = nn.Conv2d(64, OUTPUT_CHANNEL, kernel_size=1, padding=0)\n",
        "        self.outputs = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\" Encoder \"\"\"\n",
        "        s1 = self.e1(inputs)\n",
        "        s2 = self.e2(s1)\n",
        "        s3 = self.e3(s2)\n",
        "        s4 = self.e4(s3)\n",
        "\n",
        "        \"\"\" Bottleneck \"\"\"\n",
        "        b1 = self.b1(s4)\n",
        "\n",
        "        \"\"\" Decoder \"\"\"\n",
        "        d1 = self.d1(b1, s4)\n",
        "        d2 = self.d2(d1, s3)\n",
        "        d3 = self.d3(d2, s2)\n",
        "        d4 = self.d4(d3, s1)\n",
        "        \n",
        "        logits = self.logits(d4)\n",
        "        \n",
        "        \"\"\" Classifier \"\"\"\n",
        "        outputs = self.outputs(logits)\n",
        "        \n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvN6IfQohBcz"
      },
      "outputs": [],
      "source": [
        "model_torch = build_vgg16_unet_torch()\n",
        "\n",
        "model_torch.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWqQ0uYXhBcz"
      },
      "outputs": [],
      "source": [
        "summary(model_torch, input_size=INPUT_SHAPE, batch_size=-1, device='cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJW9camChBcz"
      },
      "source": [
        "### Metric, Loss and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPUDq50khBcz"
      },
      "outputs": [],
      "source": [
        "# Dice Coefficient Metric\n",
        "def dice_coef(y_true, y_pred, smooth=1.):\n",
        "    batch_size = y_pred.size(0)\n",
        "    y_true_f = y_true.view(batch_size, -1).float()  # Flatten\n",
        "    y_pred_f = y_pred.view(batch_size, -1).float()  # Flatten\n",
        "    intersection = (y_true_f * y_pred_f).sum().float()\n",
        "    return (2. * intersection + smooth) / (y_true_f.sum() + y_pred_f.sum() + smooth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prbptq2MhBcz"
      },
      "outputs": [],
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(filter(lambda param: param.requires_grad, model_torch.parameters()), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3qydpYwhBc0"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, device):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.history = {\n",
        "            \"loss\" : [],\n",
        "            \"val_loss\" : [],\n",
        "            \"accuracy\" : [],\n",
        "            \"val_accuracy\" : [],\n",
        "            \"precision\" : [],\n",
        "            \"val_precision\" : [],\n",
        "            \"recall\" : [],\n",
        "            \"val_recall\" : [],\n",
        "            \"dice_coef\" : [],\n",
        "            \"val_dice_coef\" : [],\n",
        "            \"lr\" : []\n",
        "        }\n",
        "        self.is_compiled = False\n",
        "        \n",
        "    def compile(self, criterion, optimizer, metrics):\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.accuracy = metrics[\"accuracy\"]\n",
        "        self.precision = metrics[\"precision\"]\n",
        "        self.recall = metrics[\"recall\"]\n",
        "        self.dice_coef = metrics[\"dice_coef\"]   \n",
        "        \n",
        "        self.is_compiled = True\n",
        "        \n",
        "    \n",
        "    def calculate_metrics(self, preds, targets):\n",
        "        preds = preds.to('cpu')\n",
        "        targets = targets.to('cpu') > 0.5\n",
        "        acc = self.accuracy(preds, targets, average='samples')\n",
        "        pre = self.precision(preds, targets, average='samples')\n",
        "        re = self.recall(preds, targets, average='samples')\n",
        "        dice_coef = self.dice_coef(targets, preds)\n",
        "        \n",
        "        return acc, pre, re, dice_coef\n",
        "        \n",
        "    def epoch_runner(self, epoch, num_epochs, mode, dataloader, total_len):\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        running_accuracy = 0.0\n",
        "        running_precision = 0.0\n",
        "        running_recall = 0.0\n",
        "        running_dice_coef = 0.0\n",
        "        \n",
        "        pbar = tqdm(enumerate(dataloader), total=len(dataloader), leave=True)\n",
        "        pbar_postfix_keys = {\n",
        "            key: key if mode == 'train' else f'{mode}_{key}'\n",
        "            for key in ['loss', 'accuracy', 'precision', 'recall', 'dice_coef']\n",
        "        }\n",
        "        pbar_postfix_keys['lr'] = 'lr'\n",
        "\n",
        "        for batch_idx, (inputs, targets) in pbar:\n",
        "            batch_size = inputs.size(0)\n",
        "            inputs = inputs.to(device=self.device, non_blocking=True)\n",
        "            targets = targets.to(device=self.device, non_blocking=True) \n",
        "            \n",
        "            if mode == 'train':\n",
        "                self.model.train()\n",
        "                # forward\n",
        "                preds = self.model(inputs)\n",
        "                loss = self.criterion(preds, targets)\n",
        "        \n",
        "                # backward\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "        \n",
        "                # gradient descent/ Adam step\n",
        "                self.optimizer.step()\n",
        "            \n",
        "            elif mode == 'val':\n",
        "                self.model.eval()\n",
        "                # forward\n",
        "                with torch.no_grad():\n",
        "                    preds = self.model(inputs)\n",
        "                    loss = self.criterion(preds, targets)\n",
        "                \n",
        "            # calculate custom metrics (averaged by batch_size)\n",
        "            acc, pre, re, dice_coef = self.calculate_metrics(preds, targets)\n",
        "            \n",
        "            # update running vars\n",
        "            running_loss += loss.item() * batch_size\n",
        "            running_accuracy += acc.item() * batch_size\n",
        "            running_precision += pre.item() * batch_size\n",
        "            running_recall += re.item() * batch_size\n",
        "            running_dice_coef += dice_coef.item() * batch_size\n",
        "            \n",
        "            # update progress bar\n",
        "            pbar.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "            \n",
        "            if batch_idx < len(dataloader) - 1:\n",
        "                # for all batches except for the last batch\n",
        "                # averaged by batch_size\n",
        "                pbar.set_postfix({\n",
        "                    pbar_postfix_keys[\"loss\"] : loss.item(),\n",
        "                    pbar_postfix_keys[\"accuracy\"] : acc.item(),\n",
        "                    pbar_postfix_keys[\"precision\"] : pre.item(),\n",
        "                    pbar_postfix_keys[\"recall\"] : re.item(),\n",
        "                    pbar_postfix_keys[\"dice_coef\"] : dice_coef.item(),\n",
        "                    pbar_postfix_keys['lr'] : self.optimizer.param_groups[0]['lr']\n",
        "                })\n",
        "                \n",
        "            else:\n",
        "                # last batch -> thus dispaly total epoch loss & metrics\n",
        "                epoch_loss = running_loss / total_len\n",
        "                epoch_accuracy = running_accuracy / total_len\n",
        "                epoch_precision = running_precision / total_len\n",
        "                epoch_recall = running_recall / total_len\n",
        "                epoch_dice_coef = running_dice_coef / total_len\n",
        "                \n",
        "                pbar.set_postfix({\n",
        "                    pbar_postfix_keys[\"loss\"] : epoch_loss,\n",
        "                    pbar_postfix_keys[\"accuracy\"] : epoch_accuracy,\n",
        "                    pbar_postfix_keys[\"precision\"] : epoch_precision,\n",
        "                    pbar_postfix_keys[\"recall\"] : epoch_recall,\n",
        "                    pbar_postfix_keys[\"dice_coef\"] : epoch_dice_coef,\n",
        "                    pbar_postfix_keys['lr'] : self.optimizer.param_groups[0]['lr']\n",
        "                })\n",
        "        \n",
        "        self.lr = self.optimizer.param_groups[0]['lr']\n",
        "        \n",
        "        return (\n",
        "            epoch_loss,\n",
        "            epoch_accuracy,\n",
        "            epoch_precision,\n",
        "            epoch_recall,\n",
        "            epoch_dice_coef\n",
        "        )   \n",
        "            \n",
        "    def fit(self, num_epochs, train_dataloader, total_train_len, val_dataloader=None, total_val_len=None):\n",
        "        \n",
        "        if not self.is_compiled:\n",
        "            raise Exception(\"Please compile first!\")\n",
        "        \n",
        "        for epoch in range(num_epochs):\n",
        "            # Train set\n",
        "            mode = 'train'\n",
        "            loss, acc, pre, re, dice_coef = self.epoch_runner(\n",
        "                                                    epoch, \n",
        "                                                    num_epochs,\n",
        "                                                    mode,\n",
        "                                                    train_dataloader, \n",
        "                                                    total_train_len\n",
        "                                                )\n",
        "            \n",
        "            self.history[\"loss\"].append(loss)\n",
        "            self.history[\"accuracy\"].append(acc)\n",
        "            self.history[\"precision\"].append(pre)\n",
        "            self.history[\"recall\"].append(re)\n",
        "            self.history[\"dice_coef\"].append(dice_coef)\n",
        "            self.history[\"lr\"].append(self.lr)\n",
        "            \n",
        "            # Validation set\n",
        "            if val_dataloader is not None:\n",
        "                mode = 'val'\n",
        "                val_loss, val_acc, val_pre, val_re, val_dice_coef = self.epoch_runner(\n",
        "                                                                            epoch, \n",
        "                                                                            num_epochs,\n",
        "                                                                            mode,\n",
        "                                                                            val_dataloader, \n",
        "                                                                            total_val_len\n",
        "                                                                        )\n",
        "                \n",
        "                self.history[\"val_loss\"].append(val_loss)\n",
        "                self.history[\"val_accuracy\"].append(val_acc)\n",
        "                self.history[\"val_precision\"].append(val_pre)\n",
        "                self.history[\"val_recall\"].append(val_re)\n",
        "                self.history[\"val_dice_coef\"].append(val_dice_coef)\n",
        "                \n",
        "        return self.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owD7Y5yhhBc0"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(model_torch, device)\n",
        "trainer.compile(\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    metrics={\n",
        "        \"accuracy\" : accuracy, \n",
        "        \"precision\": precision, \n",
        "        \"recall\": recall,\n",
        "        \"dice_coef\" : dice_coef\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSbAB4zNhBc0"
      },
      "outputs": [],
      "source": [
        "history = trainer.fit(num_epochs,\n",
        "                      train_dataloader,\n",
        "                      total_train_len,\n",
        "                      val_dataloader=val_dataloader,\n",
        "                      total_val_len=total_val_len\n",
        "                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UMgS2KnhBc0"
      },
      "source": [
        "### save pytorch model along with optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEIyeo8rhBc0"
      },
      "outputs": [],
      "source": [
        "checkpoint = {\n",
        "    'state_dict': trainer.model.state_dict(),\n",
        "    'optimizer': trainer.optimizer.state_dict()\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, \"./saved_model/pytorch/model_torch.pth.tar\")\n",
        "\n",
        "# only save model\n",
        "# torch.save(trainer.model.state_dict(), \"./saved_model/pytorch/model_torch.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv30b7fphBc1"
      },
      "source": [
        "### load pytorch model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7Fxpdo_hBc1"
      },
      "outputs": [],
      "source": [
        "# load pytorch model\n",
        "checkpoint = torch.load(\"./saved_model/pytorch/model_torch.pth.tar\")\n",
        "\n",
        "model_torch.load_state_dict(checkpoint['state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HekVXdcFhBc1"
      },
      "source": [
        "### save & load history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHAfPbhShBc1"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('history.pickle', 'wb') as handle:\n",
        "    pickle.dump(trainer.history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('history.pickle', 'rb') as handle:\n",
        "    b = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwz9Qw0chBc1"
      },
      "source": [
        "### Loss and Metrics Visualization "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gx3vEDlMhBc1"
      },
      "outputs": [],
      "source": [
        "acc = history['accuracy']\n",
        "val_acc = history['val_accuracy']\n",
        "loss = history['loss']\n",
        "val_loss = history['val_loss']\n",
        "dice_coef = history['dice_coef']\n",
        "val_dice_coef = history['val_dice_coef']\n",
        "epochs = range(len(acc))\n",
        "\n",
        "# Accuracy\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "# Loss\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "# Dice Coef\n",
        "plt.plot(epochs, dice_coef, 'r', label='Training Dice coef')\n",
        "plt.plot(epochs, val_dice_coef, 'b', label='Validation Dice coef')\n",
        "plt.title('Training and validation dice coef')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GWrGUoDhBc2"
      },
      "source": [
        "### Evaluation (on test set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc_iel19hBc2"
      },
      "outputs": [],
      "source": [
        "def intersection_over_union(y_true, y_pred):\n",
        "    \"\"\" Function to calculate IOU \"\"\"\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true.ravel(), y_pred.ravel()).ravel()\n",
        "    iou = tp/(tp + fp + fn)\n",
        "    return iou\n",
        "\n",
        "\n",
        "def save_results(image, mask, y_pred, save_image_path):\n",
        "    \"\"\" Fucntion that saves the original image, ground truth mask, predicted mask\"\"\"\n",
        "    \n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    line = np.ones((H, 10, 3)) * 128\n",
        "\n",
        "    mask = np.expand_dims(mask, axis=-1)    # (224, 224, 1)\n",
        "    mask = np.concatenate([mask, mask, mask], axis=-1)  # (224, 224, 3)\n",
        "    mask = mask * 255\n",
        "\n",
        "    y_pred = np.expand_dims(y_pred, axis=-1)    # (224, 224, 1)\n",
        "    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1)  # (224, 224, 3)\n",
        "    y_pred = y_pred * 255\n",
        "\n",
        "    cat_images = np.concatenate([image, line, mask, line, y_pred], axis=1)\n",
        "    cv2.imwrite(save_image_path, cat_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kS0CAuM2hBc2"
      },
      "outputs": [],
      "source": [
        "model_torch.eval()\n",
        "\n",
        "# Evaluation on test set\n",
        "SCORE = []\n",
        "for x, y in tqdm(zip(test_images, test_masks), total=len(test_masks)):\n",
        "    # Extract the name\n",
        "    if os.name == 'nt': # windows\n",
        "        name = x.split(\"\\\\\")[-1].split(\".\")[0]\n",
        "    else: # Linux\n",
        "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
        "    \n",
        "    # Reading the image\n",
        "    image = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (H, W))\n",
        "    x = np.moveaxis(image, -1, 0)\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = torch.from_numpy(x).to(device) \n",
        "\n",
        "    # Reading the mask\n",
        "    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
        "    mask = mask/255.0\n",
        "    mask = cv2.resize(mask, (H, W))\n",
        "    mask = mask.astype(np.int32)\n",
        "\n",
        "    # Prediction\n",
        "    with torch.no_grad():\n",
        "        y_pred = model_torch(x)[0]\n",
        "        \n",
        "    y_pred = y_pred.cpu().detach().numpy()\n",
        "    y_pred = np.squeeze(y_pred, axis=0)\n",
        "    y_pred = y_pred > 0.5\n",
        "    y_pred = y_pred.astype(np.int32)\n",
        "\n",
        "    # Saving the prediction\n",
        "    save_image_path = os.path.join(\"results\", \"pytorch\", f\"{name}.png\")\n",
        "    save_results(image, mask, y_pred, save_image_path)\n",
        "\n",
        "    # Flatten the array\n",
        "    mask = mask.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "\n",
        "    # Calculating the metrics values\n",
        "    acc_value = accuracy_score(mask, y_pred)\n",
        "    iou = intersection_over_union(mask, y_pred)\n",
        "    recall_value = recall_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    precision_value = precision_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n",
        "    SCORE.append([name, acc_value, iou, recall_value, precision_value])\n",
        "\n",
        "# Metrics values\n",
        "score = [s[1:] for s in SCORE]\n",
        "score = np.mean(score, axis=0)\n",
        "print(f\"Accuracy: {score[0]:0.5f}\")\n",
        "print(f\"IOU: {score[1]:0.5f}\")\n",
        "print(f\"Recall: {score[2]:0.5f}\")\n",
        "print(f\"Precision: {score[3]:0.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DumwFTlQhBc2"
      },
      "source": [
        "### Webcam Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdR9l5uwhBc3"
      },
      "outputs": [],
      "source": [
        "model_torch.eval()\n",
        "\n",
        "BG_COLOR = [0, 255, 0]  # [R, G, B]\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "    \n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    \n",
        "    if ret == False:\n",
        "        cap.release()\n",
        "        break\n",
        "\n",
        "    h, w, _ = frame.shape\n",
        "    ori_frame = frame\n",
        "    frame = cv2.resize(frame, (H, W))\n",
        "    frame = np.moveaxis(frame, -1, 0)\n",
        "    frame = np.expand_dims(frame, axis=0)\n",
        "    frame = frame / 255.0\n",
        "    frame = frame.astype(np.float32)\n",
        "    frame = torch.from_numpy(frame).to(device) \n",
        "    \n",
        "    # prediction\n",
        "    with torch.no_grad():\n",
        "        mask = model_torch(frame)[0]\n",
        "    \n",
        "    mask = mask.cpu().detach().numpy()\n",
        "    mask = np.squeeze(mask, axis=0)\n",
        "    mask = cv2.resize(mask, (w, h))\n",
        "    mask = mask > 0.5\n",
        "    mask = mask.astype(np.float32)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "\n",
        "    photo_mask = mask\n",
        "    background_mask = np.abs(1-mask)\n",
        "\n",
        "    masked_frame = ori_frame * photo_mask\n",
        "\n",
        "    background_mask = np.concatenate([background_mask, background_mask, background_mask], axis=-1)\n",
        "    background_mask = background_mask * BG_COLOR\n",
        "    final_frame = masked_frame + background_mask\n",
        "    final_frame = final_frame.astype(np.uint8)\n",
        "        \n",
        "    cv2.imshow('Window', final_frame)\n",
        "      \n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46WV6bkshBc3"
      },
      "source": [
        "### Save as torchscript model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upGY5MzjhBc3"
      },
      "outputs": [],
      "source": [
        "# 1. using script\n",
        "#    -> converts model by analyzing your python code\n",
        "#    -> preserves control flow (condition, loops,etc - for e.g if/for loop in forward function)\n",
        "#    -> May not cover 100% of operators\n",
        "\n",
        "print(\"-----[USING SCRIPT]-----\")\n",
        "scripted_model = torch.jit.script(model_torch)\n",
        "scripted_model.save('./saved_model/torchscript/scripted_model.pt')\n",
        "# print(scripted_model.code)\n",
        "print(\"-----[SCRIPT SAVED]-----\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "\n",
        "# 2. using trace\n",
        "#    -> requires a sample input to trace the computaion path\n",
        "#    -> does not preserve control flow\n",
        "#    -> works with just about any code\n",
        "\n",
        "print(\"-----[USING TRACE]-----\")\n",
        "sample_input = torch.rand(INPUT_SHAPE).unsqueeze(0).to(device=device)\n",
        "traced_model = torch.jit.trace(model_torch, sample_input)\n",
        "traced_model.save('./saved_model/torchscript/traced_model.pt')\n",
        "print(\"-----[TRACE SAVED]-----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNb_jAsChBc3"
      },
      "outputs": [],
      "source": [
        "# load scripted/traced model\n",
        "# scriptedmodel = torch.jit.load('./saved_model/torchscript/scripted_model.pt')\n",
        "tracedmodel = torch.jit.load('./saved_model/torchscript/traced_model.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Portrait_Segmentation_TF_&_Torch.ipynb",
      "provenance": []
    },
    "coursera": {
      "course_slug": "convolutional-neural-networks-tensorflow",
      "graded_item_id": "uAPOR",
      "launcher_item_id": "e9lTb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
